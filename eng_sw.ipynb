{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto:\n",
    "Como Analista de Fraude de uma empresa de seguros de carro, preciso de uma solução eficiente que utilize machine learning para detectar fraudes em grandes volumes de dados, a fim de melhorar a precisão na identificação de atividades fraudulentas e minimizar perdas financeiras para a empresa.\n",
    "\n",
    "Descrição: Como Analista de Fraude, Eu quero um aplicativo em Python que utilize técnicas de machine learning para analisar dados de seguros de carro, Para que eu possa detectar possíveis fraudes de maneira eficiente e eficaz.\n",
    "\n",
    "# Critérios de Aceitação:\n",
    "# Importação e Preparação de Dados:\n",
    "O aplicativo deve permitir a importação de dados de seguros a partir de arquivos CSV, Excel ou de um banco de dados.\n",
    "Deve realizar a limpeza dos dados, incluindo o tratamento de valores nulos e inconsistências.\n",
    "Deve realizar a transformação dos dados categóricos em formatos numéricos utilizáveis pelo modelo de machine learning.\n",
    "# Treinamento do Modelo:\n",
    "O aplicativo deve oferecer a opção de treinar um modelo de machine learning utilizando um dataset histórico de seguros previamente identificado como legítimo ou fraudulento.\n",
    "Deve incluir a divisão do dataset em conjuntos de treinamento e teste, e permitir a escolha do algoritmo de machine learning (e.g., Random Forest, Gradient Boosting, CatBoost).\n",
    "# Detecção de Fraude:\n",
    "O aplicativo deve ser capaz de aplicar o modelo treinado para prever a probabilidade de fraude em novos dados de seguros.\n",
    "Deve gerar uma lista de registros com suas respectivas probabilidades de serem fraudulentos, destacando os casos com maior risco.\n",
    "# Relatórios e Visualizações:\n",
    "O aplicativo deve fornecer relatórios detalhados com métricas de performance do modelo (e.g., precisão, recall, F1-score, AUC-ROC).\n",
    "Deve oferecer visualizações interativas, como gráficos de distribuição de fraudes detectadas, importância das features no modelo e comparações entre registros fraudulentos e legítimos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler,Normalizer\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
    "from typing import Union\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Any, List\n",
    "import time\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Any, List\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection._search import ParameterSampler\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "\n",
    "\n",
    "    ### passar preprocessador \n",
    "    ###   \n",
    "    def __init__(self,df,cat_columns,date_columns,cont_columns,disc_column,label_column=None):\n",
    "        self._df=df\n",
    "        self.cat_columns= cat_columns\n",
    "        self.date_columns= date_columns\n",
    "        self.cont_columns= cont_columns\n",
    "        self.disc_columns= disc_column\n",
    "        \n",
    "        if isinstance(label_column,str):\n",
    "            label_column=[label_column]\n",
    "            \n",
    "        if label_column is not None:\n",
    "            self.labeled=True\n",
    "            self.label_column=label_column\n",
    "        else:\n",
    "            self.labeled=False\n",
    "            self.label_column=[]\n",
    "            \n",
    "        \n",
    "    def check_columns(self,all_columns,*columns_groups):\n",
    "        columns=[]\n",
    "        for group in columns_groups:\n",
    "            if group:\n",
    "                columns+=group\n",
    "        if len(all_columns)==len(columns):\n",
    "\n",
    "            raise ValueError(f\"Columns do not match: {set(all_columns).difference(columns)}\")        \n",
    "        \n",
    "       \n",
    "        Dataset.check_columns(df.columns,cat_columns,date_columns,cont_columns,disc_column,label_column)\n",
    "    \n",
    "    @property\n",
    "    def not_label_columns(self,date=False):\n",
    "        if not date:\n",
    "            return self.cat_columns+self.cont_columns+self.disc_columns\n",
    "        else:\n",
    "            return self.cat_columns+self.date_columns+self.cont_columns+self.disc_columns\n",
    "\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "    \n",
    "    @df.setter\n",
    "    def df(self,df):\n",
    "        self._df=df\n",
    "\n",
    "    def set_sample(self,sample,type,name,subtype=None):\n",
    "        if type  not in [\"train\",\"validation\",\"test\"]:\n",
    "            raise ValueError(\"Type must be train, validation or test\")\n",
    "        if name not in [\"X\",\"Y\"]:\n",
    "            raise ValueError(\"Name must be X or Y\")\n",
    "        if subtype not in [\"scaled\",None]:\n",
    "            raise ValueError(\"Subtype must be scaled or none\")\n",
    "        \n",
    "        att_name=name+\"_\"+type if subtype is None else name+\"_\"+type+\"_\"+subtype\n",
    "\n",
    "        setattr(self,att_name,sample)\n",
    "    \n",
    "    def get_sample(self,type,name,subtype=None):\n",
    "        if type  not in [\"train\",\"validation\",\"test\"]:\n",
    "            raise ValueError(\"Type must be train, validation or test\")\n",
    "        if name not in [\"X\",\"Y\"]:\n",
    "            raise ValueError(\"Name must be X or Y\")\n",
    "        if subtype not in [\"scaled\",None]:\n",
    "            raise ValueError(\"Subtype must be scaled or none\")\n",
    "\n",
    "                \n",
    "        att_name=name+\"_\"+type if subtype is None else name+\"_\"+type+\"_\"+subtype\n",
    "\n",
    "        return getattr(self,att_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Loader:\n",
    "\n",
    "    def __init__(self,path,cat_columns,date_columns,cont_columns,disc_columns,label_columns=None):\n",
    "        df=pd.read_csv(path,dtype=str)\n",
    "        self._dataset=Dataset(df,cat_columns,date_columns,cont_columns,disc_columns,label_columns)\n",
    "\n",
    "    def rename_columns(self,columns_map):\n",
    "        self._dataset.df=self._dataset.df.rename(columns=columns_map)\n",
    "        \n",
    "    @property\n",
    "    def dataset(self):\n",
    "        return self._dataset\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class   Preprocessor:\n",
    "    def __init__(self,dataset:Dataset):\n",
    "        self.dataset=dataset\n",
    "        self.df=dataset.df\n",
    "        self.cat_columns= self.dataset.cat_columns\n",
    "        self.date_columns= self.dataset.date_columns\n",
    "        self.cont_columns= self.dataset.cont_columns\n",
    "        self.disc_columns= self.dataset.disc_columns\n",
    "        self.dataset.df\n",
    "        \n",
    "    def _convert_cat(self):\n",
    "        self.df.loc[:,self.cat_columns]=self.df[self.cat_columns].astype('category')\n",
    "    \n",
    "    def _convert_date(self):\n",
    "        for col in self.date_columns:\n",
    "            self.df[col]=pd.to_datetime(self.df[col],errors='coerce')\n",
    "    \n",
    "    def _convert_cont(self):\n",
    "        self.df[self.cont_columns]=self.df[self.cont_columns].astype(float)\n",
    "  \n",
    "\n",
    "    def _covert_discrete(self):\n",
    "        self.df[self.disc_columns]=self.df[self.disc_columns].astype(float).astype(int)\n",
    "       \n",
    "\n",
    "    def fill_na(self,fill_value=\"\"):\n",
    "        self.df=self.df.fillna(fill_value)\n",
    "    \n",
    "    def na_analysis(self):\n",
    "        return self.df.isna().sum()\n",
    "    \n",
    "    def drop_na(self):\n",
    "        self.df=self.df.dropna()\n",
    "    \n",
    "    \n",
    "    def replacements(self,columns,replacements):\n",
    "        if isinstance(replacements,str):\n",
    "            replacements=[replacements]*len(columns)\n",
    "        if isinstance(columns,str):\n",
    "            columns=[columns]\n",
    "        if len(columns)!=len(replacements):\n",
    "            raise ValueError(\"Columns and replacements must have the same length\")\n",
    "\n",
    "        for column,replacement in zip(columns,replacements):\n",
    "            self.df[column]=self.df[column].str.replace(replacement,\"\")\n",
    "\n",
    "    def create_dummies(self,columns):\n",
    "        new_columns=[]\n",
    "        for column in columns: new_columns+=list(map(lambda x:column+\"_\"+x, self.df[column].unique().tolist()))\n",
    "        self.df=pd.get_dummies(self.df,columns=columns)\n",
    "        for column in columns:\n",
    "            if column in self.cat_columns:\n",
    "                self.cat_columns.remove(column)\n",
    "        self.cat_columns+=new_columns        \n",
    "    \n",
    "    def create_date(self,day_column,month_column,year_column,date_column=None):\n",
    "        if date_column is None:\n",
    "            date_column=\"data_\"+day_column.split(\"_\")[-1]\n",
    "        self.df[date_column]=pd.to_datetime(self.df[day_column].astype(float).astype(int).astype(str)\\\n",
    "                                                +\"-\"+self.df[month_column].astype(float).astype(int).astype(str)\\\n",
    "                                                +\"-\"+self.df[year_column].astype(float).astype(int).astype(str)\\\n",
    "                                        ,errors='coerce')\n",
    "        self.date_columns.append(date_column)\n",
    "    \n",
    "\n",
    "    def process_date(self):        \n",
    "        for name,func in zip([\"weekday\",\"day\",\"month\",\"year\"],[lambda x: x.dt.weekday,lambda x: x.dt.day,lambda x: x.dt.month,lambda x: x.dt.year]):\n",
    "            columns=list(map(lambda x: x+\"_\"+name,self.date_columns))\n",
    "            self.df[columns]=self.df[self.date_columns].apply(func)\n",
    "            self.disc_columns+=columns\n",
    "    \n",
    "    def process_labels(self):\n",
    "        self.df[self.dataset.label_column]=self.df[self.dataset.label_column].apply(lambda x: x.astype('category').cat.codes)\n",
    "\n",
    "    def cat_to_codes(self,columns=None):\n",
    "        if columns is None:\n",
    "            columns=self.cat_columns\n",
    "        print(columns)\n",
    "        self.df[columns]=self.df[columns].apply(lambda x: x.astype('category').cat.codes)\n",
    "        # for column in columns:\n",
    "            # self.df.iloc[:,column]=self.df[column].astype(\"category\").cat.codes\n",
    "        \n",
    "    def set_types(self):       \n",
    "        # self._convert_cat()\n",
    "        self._convert_date()\n",
    "        self._convert_cont()\n",
    "        self._covert_discrete()     \n",
    "\n",
    "    def update_dataset(self):\n",
    "        self.dataset.df=self.df\n",
    "        self.dataset.cat_columns=self.cat_columns\n",
    "        self.dataset.date_columns=self.date_columns\n",
    "        self.dataset.cont_columns=self.cont_columns\n",
    "        self.dataset.disc_columns=self.disc_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLPreprocessing():\n",
    "\n",
    "\n",
    "    def _split(X,Y,**kwargs):\n",
    "\n",
    "        X_train, X_test, Y_train, Y_test=train_test_split(X,Y,**kwargs)\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "   \n",
    "\n",
    "    def __init__(self,dataset:Dataset) -> None:\n",
    "        self.dataset=dataset\n",
    "        self.dataset.__setattr__(\"scalable_columns\",self.dataset.cont_columns+self.dataset.disc_columns)\n",
    "        self.dataset.__setattr__(\"not_scalable_columns\",self.dataset.cat_columns)\n",
    "\n",
    "    def undersample(self):\n",
    "        positive_sample_size=(self.dataset.df[self.dataset.label_column[0]]==1).sum()\n",
    "        self.dataset.__setattr__(\"full_df\",self.dataset.df)\n",
    "        self.dataset.df=pd.concat([self.dataset.df[self.dataset.df[self.dataset.label_column[0]]==0].sample(positive_sample_size),\n",
    "                                   self.dataset.df[self.dataset.df[self.dataset.label_column[0]]==1]],axis=0)\n",
    "        print(positive_sample_size)\n",
    "\n",
    "\n",
    "    def set_scaler(self,type=\"minmax\"):\n",
    "        scalers={\"minmax\":MinMaxScaler,\"standard\":StandardScaler,\"robust\":RobustScaler,\"normalizer\":RobustScaler}\n",
    "        self.scaler=scalers[type]()\n",
    "\n",
    "    def scale(self,sample=[\"train\",\"validation\",\"test\"]):\n",
    "\n",
    "        if not hasattr(self,\"scaler\"):\n",
    "            raise ValueError(\"Scaler was not set\")\n",
    "        if not hasattr(self.dataset,\"X_train\"):\n",
    "            raise ValueError(\"Train data was not set\")        \n",
    "\n",
    "        X_train_scaled=self.scaler.fit_transform(self.dataset.X_train[self.dataset.scalable_columns].astype(float))\n",
    "        X_train_scaled=pd.concat([self.dataset.X_train[self.dataset.not_scalable_columns].reset_index(drop=True),\n",
    "                                  pd.DataFrame(X_train_scaled,columns=self.dataset.scalable_columns)],axis=1)\n",
    "        self.dataset.set_sample(X_train_scaled,\"train\",\"X\",subtype=\"scaled\")\n",
    "\n",
    "        if \"test\" in sample and hasattr(self.dataset,\"X_test\"):\n",
    "            X_test_scaled=self.scaler.transform(self.dataset.X_test[self.dataset.scalable_columns])\n",
    "            X_test_scaled=pd.concat([self.dataset.X_test[self.dataset.not_scalable_columns].reset_index(drop=True),\n",
    "                                     pd.DataFrame(X_test_scaled,columns=self.dataset.scalable_columns)],axis=1)\n",
    "            self.dataset.set_sample(X_test_scaled,\"test\",\"X\",subtype=\"scaled\")\n",
    "\n",
    "        if \"validation\" in sample and hasattr(self.dataset,\"X_validation\"):\n",
    "            X_val_scaled=self.scaler.transform(self.dataset.X_validation[self.dataset.scalable_columns])\n",
    "            X_val_scaled=pd.concat([self.dataset.X_validation[self.dataset.not_scalable_columns].reset_index(drop=True),\n",
    "                                    pd.DataFrame(X_val_scaled,columns=self.dataset.scalable_columns)],axis=1)\n",
    "            self.dataset.set_sample(X_val_scaled,\"validation\",\"X\",subtype=\"scaled\")\n",
    "    \n",
    "\n",
    "    def split(self,validation=True,stratified=True,columns_stratify=None):\n",
    "\n",
    "         \n",
    "        train_size=0.7 if validation else 0.80\n",
    "        validation_size=0.15\n",
    "        test_size=0.15 if validation else 0.20\n",
    "        if not self.dataset.labeled:\n",
    "            raise NotImplemented()\n",
    "        \n",
    "        if stratified and columns_stratify is not None:            \n",
    "            columns_stratify+=self.dataset.label_column\n",
    "\n",
    "              \n",
    "        X_train, X_test, Y_train, Y_test=MLPreprocessing._split(self.dataset.df[self.dataset.not_label_columns],self.dataset.df[self.dataset.label_column],random_state=42,test_size=test_size+validation_size,stratify=columns_stratify)        \n",
    "        if validation:\n",
    "                X_test, X_val, Y_test, Y_val=MLPreprocessing._split(X_test,Y_test,random_state=42,test_size=validation_size/(test_size+validation_size),stratify=columns_stratify)\n",
    "        else:\n",
    "            X_val,Y_val=None,None\n",
    "        \n",
    "        self.dataset.set_sample(X_train,\"train\",\"X\")\n",
    "        self.dataset.set_sample(Y_train,\"train\",\"Y\")\n",
    "        self.dataset.set_sample(X_val,\"validation\",\"X\")\n",
    "        self.dataset.set_sample(Y_val,\"validation\",\"Y\")\n",
    "        self.dataset.set_sample(X_test,\"test\",\"X\")\n",
    "        self.dataset.set_sample(Y_test,\"test\",\"Y\")\n",
    "\n",
    "\n",
    "\n",
    "    def cross_validation():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(BaseEstimator):\n",
    "\n",
    "    @staticmethod\n",
    "    def camel_case_split(str):     \n",
    "        start_idx = [i for i, e in enumerate(str)\n",
    "                    if e.isupper()] + [len(str)]\n",
    "    \n",
    "        start_idx = [0] + start_idx\n",
    "        return [str[x: y] for x, y in zip(start_idx, start_idx[1:])]         \n",
    "    \n",
    "    \n",
    "    def __init__(self,model,params,supervised:bool,run_scaled:bool=False,run_on_categorical=True,run_on_continues=True,created=False) -> None:\n",
    "        self._model=model\n",
    "        self.params=params\n",
    "        self.supervised=supervised\n",
    "        if not created:\n",
    "            self.set_params()\n",
    "        else:\n",
    "            self.created=created\n",
    "        self.run_scaled=run_scaled\n",
    "        self.run_on_categorical=run_on_categorical\n",
    "        self.run_on_continues=run_on_continues\n",
    "        if not (run_on_categorical or run_on_continues):\n",
    "            raise ValueError(\"Model must run on categorical and/or continues columns\")\n",
    "        \n",
    "    def get_X(self,type:Union[\"train\",\"test\",\"validation\"],dataset:Dataset):       \n",
    "        \n",
    "        subtype=\"scaled\" if self.run_scaled else None\n",
    "        columns=dataset.not_label_columns\n",
    "        if not self.run_on_categorical:\n",
    "            columns=list(set(columns).difference(dataset.cat_columns))\n",
    "        if not self.run_on_continues:\n",
    "            columns=list(set(columns).difference(dataset.cont_columns))\n",
    "            \n",
    "        return dataset.get_sample(type,\"X\",subtype=subtype)[columns]\n",
    "    \n",
    "    def set_params(self):\n",
    "        self.created=True\n",
    "        self._model=self._model(**self.params)\n",
    "    \n",
    "    def grid_search_params(self,**params):\n",
    "        self.grid_search_params=params\n",
    "\n",
    "    def random_grid_search_params(self,**params):\n",
    "        self.grid_search_params=params\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        if not hasattr(self,\"created\"):\n",
    "            raise ValueError(\"Model was not set\")\n",
    "        \n",
    "        return self._model        \n",
    "\n",
    "    def set_metrics(self,metric,value):\n",
    "        if not hasattr(self,\"metrics\"):\n",
    "            self.metrics={}\n",
    "        self.metrics[metric]=value\n",
    "\n",
    "    def show_metrics(self):\n",
    "        return self.metrics\n",
    "    \n",
    "    def fit(self,Y,X=None,type=None,dataset:Dataset=None,**kwargs):\n",
    "        if X is None and type is not None and dataset is not None:\n",
    "            X=self.get_X(type,dataset)\n",
    "            \n",
    "        return self._model.fit(X,Y,**kwargs)\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        name=(self.model.__str__()).split(\"(\")[0]\n",
    "        if self.run_scaled:\n",
    "            name+=\"_scaled\"\n",
    "        if self.run_on_categorical:\n",
    "            name+=\"_cat\"\n",
    "        if self.run_on_continues:\n",
    "            name+=\"_cont\"\n",
    "        return name\n",
    "            \n",
    "    def __call__(self,X=None,type=None,dataset:Dataset=None):\n",
    "        if type is not None and Dataset is not None:\n",
    "            X=self.get_X(type,dataset)\n",
    "        if X is None:\n",
    "            raise ValueError(\"X or type and Dataset must be passed\")\n",
    "        \n",
    "        return self._model.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self,models:List[BaseEstimator],dataset:Dataset) -> None:\n",
    "        if not isinstance(models,list):\n",
    "            models=[models]\n",
    "            \n",
    "        self.models=models\n",
    "        self.dataset=dataset\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _train(self,model:Model,**kwargs):\n",
    "            t1=time.time()\n",
    "            if model.supervised:\n",
    "                    model.fit(type=\"train\",dataset=self.dataset,Y=self.dataset.Y_train,**kwargs)\n",
    "            \n",
    "            else:\n",
    "                    model.fit(tpe=\"train\",dataset=self.dataset,**kwargs)\n",
    "             \n",
    "            t2=time.time()\n",
    "            model.__setattr__(\"training_time\",t2-t1)\n",
    "        \n",
    "\n",
    "    def train(self,**kwargs):\n",
    "        if \"model\" not in kwargs:            \n",
    "            for model in self.models:                    \n",
    "                self._train(model,**kwargs)\n",
    "        else:\n",
    "            model=kwargs.pop(\"model\")\n",
    "            self._train(model,**kwargs)\n",
    "        \n",
    "\n",
    "\n",
    "    def run_grid_search(self,random_state=123,n_iter=10):\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "        for model in self.models:\n",
    "            if not hasattr(model,\"grid_search_params\"):\n",
    "                continue\n",
    "            else:\n",
    "                parameters=ParameterSampler(model.grid_search_params,n_iter=n_iter,random_state=random_state)\n",
    "                for param in parameters:\n",
    "                    model.copy().set_params(**param)\n",
    "                    self._train(model)\n",
    "            \n",
    "                         \n",
    "\n",
    "    def run_evaluation(self):\n",
    "        for model in self.models:\n",
    "            model.evaluate()\n",
    "\n",
    "    def add(self,model:Model,train=True):\n",
    "        self.models.append(model)\n",
    "        if train:\n",
    "            self.train(model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluation():\n",
    "    \n",
    "    def __init__(self,models:List[Model],dataset:Dataset) -> None:\n",
    "        if not isinstance(models,list):\n",
    "            models=[models]\n",
    "            \n",
    "        self.dataset=dataset\n",
    "        self.models=models\n",
    "\n",
    "\n",
    "    def run(self,sample=\"validation\"):\n",
    "        for model in self.models:\n",
    "           \n",
    "            accuracy=accuracy_score(self.dataset.Y_validation,model(type=sample,dataset=self.dataset))  \n",
    "            precision=precision_score(self.dataset.Y_validation,model(type=sample,dataset=self.dataset))\n",
    "            recall=recall_score(self.dataset.Y_validation,model(type=sample,dataset=self.dataset))\n",
    "            f1=f1_score(self.dataset.Y_validation,model(type=sample,dataset=self.dataset))\n",
    "            roc_auc=roc_auc_score(self.dataset.Y_validation,model(type=sample,dataset=self.dataset))\n",
    "\n",
    "            model.set_metrics(\"accuracy\",accuracy)\n",
    "            model.set_metrics(\"precision\",precision)\n",
    "            model.set_metrics(\"recall\",recall)\n",
    "            model.set_metrics(\"f1\",f1)\n",
    "            model.set_metrics(\"roc_auc\",roc_auc)\n",
    "\n",
    "\n",
    "    def metrics(self):\n",
    "        metrics={}\n",
    "        for model in self.models:\n",
    "            metrics[str(model)]=model.show_metrics()\n",
    "        return metrics\n",
    "    \n",
    "    def plot_metrics(self,orient=\"model\"):\n",
    "        if orient==\"model\":\n",
    "            fig,axs=plt.subplot_mosaic([[\"accuracy\",\"precision\",\"recall\"],[\"f1\",\"roc_auc\",\"vazio\"]],sharey=True,figsize=(10,4))\n",
    "            for metric in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\"]:\n",
    "                values=[]\n",
    "                for model in self.models:\n",
    "                    values.append(model.__getattribute__(\"metrics\")[metric])\n",
    "                axs[metric].set_title(metric)\n",
    "                sns.barplot(x=values,y=[str(model) for model in self.models],ax=axs[metric])\n",
    "                axs[metric].set_xlim(0.5,1)\n",
    "            plt.tight_layout()\n",
    "            return fig\n",
    "        else:\n",
    "            fig,axs=plt.subplots(len(self.models)//5+1,5,sharey=True)\n",
    "            if len(self.models)//5+1 ==1:\n",
    "                axs=axs.reshape(1,-1)\n",
    "\n",
    "            for index,model in enumerate(self.models):\n",
    "                values=[]\n",
    "                for metric in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\"]:\n",
    "                    values.append(model.__getattribute__(\"metrics\")[metric])\n",
    "                axs[index//5,index%5].set_title(model.model,fontsize=8)\n",
    "                sns.barplot(x=values,y=[\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\"],ax=axs[index//5,index%5])\n",
    "            plt.tight_layout()\n",
    "            return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector():\n",
    "    \n",
    "    def __init__(self,models:List[Model],aimed_metric=\"accuracy\") -> None:\n",
    "        if not isinstance(models,list):\n",
    "            models=[models]\n",
    "        \n",
    "        self.models=models\n",
    "        self.aimed_metric=aimed_metric\n",
    "        pass\n",
    "    \n",
    "    def check_metric(self):\n",
    "        for model in self.models:\n",
    "            if not hasattr(model,\"metrics\"):\n",
    "                raise ValueError(f\"{str(model)} has no metrics\")\n",
    "            elif model.metrics.get(self.aimed_metric) is None:\n",
    "                    raise ValueError(f\"{str(model)} has no metrics\")\n",
    "            \n",
    "    \n",
    "    def select(self):\n",
    "        scores=[]\n",
    "        for model in self.models:\n",
    "            scores.append(model.metrics.get(self.aimed_metric))\n",
    "        \n",
    "        argmax=scores.index(max(scores))\n",
    "\n",
    "        return self.models[argmax]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTunning:\n",
    "    \n",
    "    @staticmethod\n",
    "    def ideal_cutoff(size,cutoff,max_iter):\n",
    "        \n",
    "        if size*cutoff>max_iter:\n",
    "            cutoff-=1\n",
    "            return ModelTunning.ideal_cutoff(size,cutoff,max_iter)\n",
    "            #return cutoff\n",
    "        else:\n",
    "            return cutoff\n",
    "    def __init__(self,model:Model,dataset:Dataset,cv=10,random_state=123,scoring_fn=\"accuracy\") -> None:\n",
    "        self.model=model\n",
    "        self.dataset=dataset\n",
    "        self.random_state=random_state\n",
    "        self.cv=cv\n",
    "        self.scoring_fn=scoring_fn\n",
    "\n",
    "    def RandomSearch(self,n_iter=10):\n",
    "        search=RandomizedSearchCV(self.model.model,self.model.grid_search_params,n_iter=n_iter,random_state=self.random_state,\n",
    "                                  scoring=self.scoring_fn,cv=self.cv)\n",
    "        \n",
    "        search.fit(self.model.get_X(type=\"train\",dataset=self.dataset),self.dataset.Y_train)\n",
    "        self.random_search=search\n",
    "        self.random_search_best_model=self.model.copy()\n",
    "        self.random_search_best_model._model=clone(self.random_search.best_estimator_)\n",
    "        return search.cv_results_\n",
    "    \n",
    "\n",
    "    \n",
    "    def GridSearch(self,max_iter=30,amplitude=0.5,cutoff=5,params=None):\n",
    "        if params is None:            \n",
    "            if not hasattr(self,\"random_search\"):\n",
    "                raise ValueError(\"Params must be passed or RandomSearch must be run\")\n",
    "            \n",
    "            params=self.random_search.best_params_\n",
    "            if max_iter<3*len(params):\n",
    "                print(\"Max_iter is less than the number of parameters. It is being set to 3 times the number of parameters\")\n",
    "                max_iter=3*len(params)\n",
    "\n",
    "            \n",
    "            cutoff=self.ideal_cutoff(len(params),cutoff,max_iter)\n",
    "        \n",
    "            for param,value in params.items():                \n",
    "                if isinstance(value,int):\n",
    "                    params[param]=np.arange(value-min(cutoff,int(value*amplitude)),value+min(cutoff,int(value*amplitude)))\n",
    "                elif isinstance(value,float):\n",
    "                    params[param]=np.arange(value-min(cutoff,value*amplitude),value+min(cutoff,value*amplitude))\n",
    "\n",
    "                    \n",
    "        fine_search=GridSearchCV(self.model.model,params,scoring=self.scoring_fn,cv=self.cv)       \n",
    "        fine_search.fit(self.model.get_X(type=\"train\",dataset=self.dataset),self.dataset.Y_train)\n",
    "        self.fine_search=fine_search\n",
    "        self.grid_search_best_model=self.model.copy()\n",
    "        self.grid_search_best_model._model=clone(self.random_search.best_estimator_)\n",
    "        return fine_search.cv_results_\n",
    "    \n",
    "    @property\n",
    "    def best_model(self):\n",
    "        if hasattr(self,\"grid_search_best_model\"):\n",
    "            return self.grid_search_best_model\n",
    "        elif hasattr(self,\"random_search_best_model\"):\n",
    "            return self.random_search_best_model\n",
    "        else:\n",
    "            raise ValueError(\"No search was run\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class orchestrator():\n",
    "\n",
    "    def __init__(self,models,loader,\n",
    "                 preprocessor_class:Preprocessor,\n",
    "                 ml_reprocessing_class:MLPreprocessing,\n",
    "                 trainer_class:Trainer,\n",
    "                 evaluation_class:Evaluation,\n",
    "                 model_tunning_class:ModelTunning,\n",
    "                 model_selector_class:Selector) -> None:\n",
    "        \n",
    "        self.models=models\n",
    "        self.loader=loader\n",
    "        self.preprocessing_class=preprocessor_class\n",
    "        self.ml_preprocessing_class=ml_reprocessing_class\n",
    "        self.trainer_class=trainer_class\n",
    "        self.evaluation_class=evaluation_class\n",
    "        self.tunning_class=model_tunning_class\n",
    "        self.model_selector_class=model_selector_class\n",
    "\n",
    "    def run_preprocessing(self,replacement_columns=[\"tamanho_motor\",\"milhas_carro\"],replacements=[\"L\",\"mile\"],\n",
    "                          adv_day_column=\"dia_aviso\",adv_month_column=\"mes_aviso\",adv_year_column=\"ano_aviso\",dumies_columns=[\"cor\",\"tipo_cambio\"]):\n",
    "        \n",
    "        preprocessor=self.preprocessing_class(self.loader.dataset)\n",
    "        preprocessor.replacements(columns=replacement_columns,replacements=replacements)\n",
    "        preprocessor.set_types()\n",
    "\n",
    "        if (adv_day_column in self.loader.dataset.df.columns and \"mes_aviso\" in self.loader.dataset.df.columns and \"ano_aviso\" in self.loader.dataset.df.columns):                \n",
    "            preprocessor.create_date(day_column=adv_day_column,month_column=adv_month_column,year_column=adv_year_column)\n",
    "        \n",
    "        if all([column in self.loader.dataset.df.columns for column in dumies_columns]):\n",
    "            preprocessor.create_dummies(dumies_columns)     \n",
    "\n",
    "        preprocessor.cat_to_codes()\n",
    "        preprocessor.process_date()\n",
    "        preprocessor.process_labels()\n",
    "        preprocessor.fill_na()\n",
    "        preprocessor.drop_na()\n",
    "        preprocessor.update_dataset()\n",
    "        return preprocessor\n",
    "\n",
    "    def run_ml_preprocessing(self,dataset,validation=True):\n",
    "        MLpreprocessor=self.ml_preprocessing_class(dataset)\n",
    "        MLpreprocessor.undersample()\n",
    "        MLpreprocessor.split(validation=validation)\n",
    "        MLpreprocessor.set_scaler()\n",
    "        MLpreprocessor.scale()\n",
    "        return MLpreprocessor\n",
    "\n",
    "    def run_trainnig(self,models,dataset):\n",
    "        trainer=self.trainer_class(models,dataset)\n",
    "        trainer.train()\n",
    "        return trainer\n",
    "    \n",
    "    def run_model_evaluation(self,models,dataset):\n",
    "        evaluator=self.evaluation_class(models,dataset)\n",
    "        evaluator.run()\n",
    "        return evaluator\n",
    "    \n",
    "    def run_model_selection(self,models,dataset,decision_metric=\"f1\"):\n",
    "        trainer=self.run_trainnig(models,dataset)\n",
    "        evaluator=self.run_model_evaluation(trainer.models,dataset)\n",
    "        best_model=self.model_selector_class(evaluator.models,decision_metric).select()\n",
    "        return trainer,evaluator,best_model\n",
    "\n",
    "\n",
    "    def run_tunning(self,model,dataset,cv=3,random_n_iter=10,grid_max_iter=10)->Model:\n",
    "        tunning=self.tunning_class(model,dataset,cv=cv,random_state=123,scoring_fn=\"roc_auc\")\n",
    "        tunning.RandomSearch(n_iter=random_n_iter)\n",
    "        tunning.GridSearch(max_iter=grid_max_iter,amplitude=0.5,cutoff=3)\n",
    "        return tunning\n",
    "\n",
    "    def run_pipeline(self,cv,random_n_iter,grid_max_iter):\n",
    "        self.preprocessor=self.run_preprocessing()\n",
    "        self.MLpreprocessor=self.run_ml_preprocessing(self.preprocessor.dataset,validation=True)\n",
    "        self.trainer,self.evaluator,best_model=self.run_model_selection(self.models,self.preprocessor.dataset)\n",
    "        self.tunning=self.run_tunning(best_model,self.MLpreprocessor.dataset,cv=cv,random_n_iter=random_n_iter,grid_max_iter=grid_max_iter)\n",
    "        self.best_model=self.retrain_best_model()\n",
    "        return self.best_model.model\n",
    "\n",
    "    def concat_train_validation_data(self,X:List[pd.DataFrame],Y):\n",
    "        X=pd.concat(X,axis=1,ignore_index=True)\n",
    "        Y=pd.concat(Y,axis=1,ignore_index=True)\n",
    "        return X,Y\n",
    "    \n",
    "    def retrain_sbest_model(self):\n",
    "        best_model=self.tunning.best_model\n",
    "        self.bestmodel_MLpreprocessor=self.run_ml_preprocessing(self.preprocessor.dataset,validation=False)\n",
    "        self.bestmodel_trainer=self.run_trainnig(self.best_model,self.bestmodel_MLpreprocessor.dataset)\n",
    "        self.bestmodel_evaluator=self.run_model_evaluation([best_model],self.bestmodelMLpreprocessor.dataset)        \n",
    "        self.pickle_model(best_model.model)\n",
    "        return best_model\n",
    "\n",
    "            \n",
    "    def pickle_model(self,model,filename=\"best_model.pkl\"):\n",
    "        pickle.dump(model,open(filename,\"wb\"))\n",
    "\n",
    "    def get_metrics(self):\n",
    "        self.best_model.show_metrics()\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        self.evaluator.plot_metrics()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map={\"Maker\":\"fabricante\",\" Genmodel\":\"modelo_carro\",\" Genmodel_ID\":\"ano_modelo_carro\",\n",
    "            \"Door_num\":\"portas\",\"Seat_num\":\"lugares\",\"repair_complexity\":\"nivel_conserto\",\n",
    "            \"repair_cost\":\"custo_conserto\",\"repair_date\":\"data_conserto\",\"repair_hours\":\"tempo_conserto\",\n",
    "            \"breakdown_date\":\"data_sinistro\",\"Fuel_type\":\"combustível\",\"Color\":\"cor\",\"Adv_year\":\"ano_aviso\",\n",
    "            \"Adv_month\":\"mes_aviso\",\"Bodytype\":\"tipo_carro\",\"issue\":\"tipo_falha\",\"issue_id\":\"categoria_falha\",\n",
    "            \"Reg_year\":\"ano_registro\",\"Engin_size\":\"tamanho_motor\",\"Gearbox\":\"tipo_cambio\",\"Adv_day\":\"dia_aviso\",\n",
    "            \"Runned_Miles\":\"milhas_carro\",\"Price\":\"preço\"}\n",
    "\n",
    "cat_columns=[\"fabricante\", 'modelo_carro', 'ano_modelo_carro', 'cor', 'tipo_carro' \n",
    "              ,'tipo_cambio', 'combustível', 'tipo_falha', 'categoria_falha','nivel_conserto']\n",
    "\n",
    "disc_columns=[\"ano_registro\",\"lugares\",\"portas\",\"dia_aviso\",'tamanho_motor','mes_aviso','ano_aviso']\n",
    "date_columns=[\"data_conserto\",\"data_sinistro\",]\n",
    "cont_columns=['preço','tempo_conserto',\"milhas_carro\",\"custo_conserto\"]\n",
    "label_columns=[\"Label\"]\n",
    "\n",
    "\n",
    "loader=Loader('vehicle_claims_labeled.csv',cat_columns=cat_columns,date_columns=date_columns,cont_columns=cont_columns,disc_columns=disc_columns,label_columns=label_columns)\n",
    "loader.rename_columns(columns_map)\n",
    "\n",
    "\n",
    "\n",
    "KNN=Model(KNeighborsClassifier,params={},supervised=True,run_scaled=False)\n",
    "KNN.grid_search_params(n_neighbors=range(3,25,2),weights=[\"uniform\",\"distance\"])\n",
    "LR=Model(LogisticRegression,params={},supervised=True,run_scaled=False)\n",
    "LR.random_grid_search_params(C=np.logspace(-4,4,20),penalty=[\"l1\",\"l2\"])\n",
    "NB=Model(GaussianNB,params={},supervised=True,run_scaled=True)\n",
    "NB.random_grid_search_params(n_features_in=range(3,20),var_smoothing=np.logspace(-9,-1,20))\n",
    "models=[KNN,LR,NB]\n",
    "ml_pipeline=orchestrator(models,loader,Preprocessor,MLPreprocessing,Trainer,Evaluation,ModelTunning,Selector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipeline.run_pipeline(cv=3,random_n_iter=3,grid_max_iter=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
